{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Deduplication using Clustering\n",
    "**Objective**: Learn and implement data deduplication techniques.\n",
    "\n",
    "**Task**: DBSCAN for Data Deduplication\n",
    "\n",
    "**Steps**:\n",
    "1. Data Set: Download a dataset containing duplicate entries for event registrations.\n",
    "2. DBSCAN Clustering: Apply the DBSCAN algorithm to cluster similar registrations.\n",
    "3. Identify Duplicates: Detect duplicates based on density of the clusters.\n",
    "4. Refinement: Validate clusters and remove any erroneous duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.016s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Data with Clusters:\n",
      "      name                email  cluster\n",
      "0    Alice    alice@example.com        0\n",
      "1      Bob      bob@example.com       -1\n",
      "2    Alice    alice@example.com        0\n",
      "3  Charlie  charlie@example.com       -1\n",
      "4    David    david@example.com        0\n",
      "5      Eve      eve@example.com       -1\n",
      "6    Alice    alice@example.com        0\n",
      "\n",
      "Potential Duplicates:\n",
      "    name              email  phone  email_length  cluster\n",
      "0  Alice  alice@example.com    123            17        0\n",
      "2  Alice  alice@example.com    123            17        0\n",
      "4  David  david@example.com    101            17        0\n",
      "6  Alice  alice@example.com    123            17        0\n",
      "\n",
      "Refined Data (without noise):\n",
      "    name              email  phone  email_length  cluster\n",
      "0  Alice  alice@example.com    123            17        0\n",
      "2  Alice  alice@example.com    123            17        0\n",
      "4  David  david@example.com    101            17        0\n",
      "6  Alice  alice@example.com    123            17        0\n",
      "Error loading data: Input data contains missing values.\n"
     ]
    }
   ],
   "source": [
    "# Install required library\n",
    "!pip install -q scikit-learn pandas\n",
    "\n",
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import unittest\n",
    "\n",
    "# Sample dataset with potential duplicates (e.g., names, registration details)\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Alice', 'Charlie', 'David', 'Eve', 'Alice'],\n",
    "    'email': ['alice@example.com', 'bob@example.com', 'alice@example.com', 'charlie@example.com', \n",
    "              'david@example.com', 'eve@example.com', 'alice@example.com'],\n",
    "    'phone': ['123', '456', '123', '789', '101', '112', '123'],\n",
    "}\n",
    "\n",
    "# Function to load data safely and check for issues\n",
    "def load_data(data):\n",
    "    try:\n",
    "        df = pd.DataFrame(data)\n",
    "        if df.isnull().values.any():\n",
    "            raise ValueError(\"Input data contains missing values.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Load data and validate\n",
    "df = load_data(data)\n",
    "if df.empty:\n",
    "    raise ValueError(\"Data loading failed. Empty DataFrame returned.\")\n",
    "\n",
    "# Preprocessing function with validation and error handling\n",
    "def preprocess_data(df):\n",
    "    try:\n",
    "        # Convert phone to numeric, handle errors gracefully\n",
    "        df['phone'] = pd.to_numeric(df['phone'], errors='coerce')\n",
    "        \n",
    "        # Add email_length as a feature\n",
    "        df['email_length'] = df['email'].apply(len)\n",
    "\n",
    "        if df[['phone', 'email_length']].isnull().values.any():\n",
    "            raise ValueError(\"Data contains NaN values after preprocessing.\")\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocessing: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Apply preprocessing\n",
    "df = preprocess_data(df)\n",
    "if df.empty:\n",
    "    raise ValueError(\"Preprocessing failed. Empty DataFrame returned.\")\n",
    "\n",
    "# Define DBSCAN parameters\n",
    "EPSILON = 0.5  # Max distance between two samples for them to be considered as in the same neighborhood\n",
    "MIN_SAMPLES = 2  # The minimum number of points required to form a cluster\n",
    "\n",
    "# DBSCAN clustering function with error handling\n",
    "def apply_dbscan(df):\n",
    "    try:\n",
    "        # Standardize the numerical features\n",
    "        scaler = StandardScaler()\n",
    "        df_scaled = scaler.fit_transform(df[['phone', 'email_length']])\n",
    "\n",
    "        # Apply DBSCAN clustering\n",
    "        db = DBSCAN(eps=EPSILON, min_samples=MIN_SAMPLES, metric='euclidean')\n",
    "        df['cluster'] = db.fit_predict(df_scaled)\n",
    "        \n",
    "        if df['cluster'].isnull().values.any():\n",
    "            raise ValueError(\"DBSCAN clustering failed. NaN values in cluster.\")\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error in DBSCAN clustering: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Apply DBSCAN\n",
    "df = apply_dbscan(df)\n",
    "if df.empty:\n",
    "    raise ValueError(\"DBSCAN failed. Empty DataFrame returned.\")\n",
    "\n",
    "# Identify potential duplicates based on cluster\n",
    "def identify_duplicates(df):\n",
    "    duplicates = df[df['cluster'] > -1]  # Only clusters with values greater than -1 are considered duplicates\n",
    "    return duplicates\n",
    "\n",
    "# Identify duplicates\n",
    "duplicates = identify_duplicates(df)\n",
    "\n",
    "# Print the results\n",
    "print(\"\\nOriginal Data with Clusters:\")\n",
    "print(df[['name', 'email', 'cluster']])\n",
    "print(\"\\nPotential Duplicates:\")\n",
    "print(duplicates)\n",
    "\n",
    "# Refining duplicates (removing noise, if needed)\n",
    "refined_df = df[df['cluster'] > -1]\n",
    "print(\"\\nRefined Data (without noise):\")\n",
    "print(refined_df)\n",
    "\n",
    "# Unit tests for the functions\n",
    "class TestDataProcessing(unittest.TestCase):\n",
    "\n",
    "    def test_load_data_valid(self):\n",
    "        valid_data = {'name': ['Alice', 'Bob'], 'email': ['alice@example.com', 'bob@example.com'], 'phone': ['123', '456']}\n",
    "        df = load_data(valid_data)\n",
    "        self.assertFalse(df.empty)\n",
    "    \n",
    "    def test_load_data_invalid(self):\n",
    "        invalid_data = {'name': ['Alice', None], 'email': ['alice@example.com', 'bob@example.com'], 'phone': ['123', '456']}\n",
    "        df = load_data(invalid_data)\n",
    "        self.assertTrue(df.empty)\n",
    "    \n",
    "    def test_preprocess_data(self):\n",
    "        data = {'name': ['Alice'], 'email': ['alice@example.com'], 'phone': ['123']}\n",
    "        df = load_data(data)\n",
    "        df = preprocess_data(df)\n",
    "        self.assertFalse(df[['phone', 'email_length']].isnull().values.any())\n",
    "    \n",
    "    def test_dbscan_cluster(self):\n",
    "        data = {'name': ['Alice', 'Bob'], 'email': ['alice@example.com', 'bob@example.com'], 'phone': ['123', '456']}\n",
    "        df = load_data(data)\n",
    "        df = preprocess_data(df)\n",
    "        df = apply_dbscan(df)\n",
    "        self.assertTrue('cluster' in df.columns)\n",
    "    \n",
    "    def test_identify_duplicates(self):\n",
    "        data = {'name': ['Alice', 'Bob', 'Alice'], 'email': ['alice@example.com', 'bob@example.com', 'alice@example.com'], 'phone': ['123', '456', '123']}\n",
    "        df = load_data(data)\n",
    "        df = preprocess_data(df)\n",
    "        df = apply_dbscan(df)\n",
    "        duplicates = identify_duplicates(df)\n",
    "        self.assertGreater(len(duplicates), 0)\n",
    "\n",
    "# Run unit tests\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], exit=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

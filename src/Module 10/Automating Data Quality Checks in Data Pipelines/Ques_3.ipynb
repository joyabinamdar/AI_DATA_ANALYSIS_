{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Data Quality Monitoring\n",
    "**Objective**: Use Great Expectations to perform data profiling and write validation rules.\n",
    "\n",
    "1. Data Profiling with Great Expectations\n",
    "\n",
    "### Profile a JSON dataset with product sales data to check for null values in the 'ProductID' and 'Price' fields.\n",
    "- Create an expectation suite and connect it to the data context.\n",
    "- Use the `expect_column_values_to_not_be_null` expectation to profile these fields.\n",
    "- Review the summary to identify any unexpected null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking file...\n",
      "‚ùå Erro\n"
     ]
    }
   ],
   "source": [
    "# write your code from here\n",
    "import os\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "from great_expectations.data_context import FileDataContext\n",
    "from great_expectations.exceptions import GreatExpectationsError\n",
    "\n",
    "# === Configuration ===\n",
    "GE_PATH = \"great_expectations\"\n",
    "JSON_PATH = \"data/product_sales.json\"  # Update path to your JSON file\n",
    "SUITE_NAME = \"product_sales_suite\"\n",
    "DATASOURCE_NAME = \"my_json_datasource\"\n",
    "DATA_ASSET_NAME = \"product_sales.json\"\n",
    "CONNECTOR_NAME = \"default_inferred_data_connector_name\"\n",
    "\n",
    "# === Helper Functions ===\n",
    "\n",
    "def validate_file_exists(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "\n",
    "def load_context(path):\n",
    "    try:\n",
    "        return FileDataContext(path)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load GE context: {e}\")\n",
    "\n",
    "def configure_datasource(context):\n",
    "    # Optional: set up a new datasource via CLI or config if not already done\n",
    "    # You can skip this in the script if datasource is already configured\n",
    "    print(\"‚úîÔ∏è Ensure your JSON datasource is registered via GE CLI or YAML.\")\n",
    "\n",
    "def get_validator(context):\n",
    "    batch_request = {\n",
    "        \"datasource_name\": DATASOURCE_NAME,\n",
    "        \"data_connector_name\": CONNECTOR_NAME,\n",
    "        \"data_asset_name\": DATA_ASSET_NAME,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        validator = context.get_validator(\n",
    "            batch_request=batch_request,\n",
    "            expectation_suite_name=SUITE_NAME\n",
    "        )\n",
    "        return validator\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to create validator: {e}\")\n",
    "\n",
    "def define_null_expectations(validator):\n",
    "    validator.expect_column_to_exist(\"ProductID\")\n",
    "    validator.expect_column_to_exist(\"Price\")\n",
    "\n",
    "    validator.expect_column_values_to_not_be_null(\"ProductID\")\n",
    "    validator.expect_column_values_to_not_be_null(\"Price\")\n",
    "\n",
    "    validator.save_expectation_suite()\n",
    "\n",
    "def build_docs(context):\n",
    "    context.build_data_docs()\n",
    "    print(\"üìÑ Data Docs available at: great_expectations/uncommitted/data_docs/local_site/index.html\")\n",
    "\n",
    "# === Main Execution ===\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"üîç Checking file...\")\n",
    "        validate_file_exists(JSON_PATH)\n",
    "\n",
    "        print(\"üìÇ Loading context...\")\n",
    "        context = load_context(GE_PATH)\n",
    "\n",
    "        print(\"üßæ Connecting to JSON data...\")\n",
    "        configure_datasource(context)\n",
    "\n",
    "        print(\"üß™ Creating validator...\")\n",
    "        validator = get_validator(context)\n",
    "\n",
    "        print(\"‚úÖ Defining expectations...\")\n",
    "        define_null_expectations(validator)\n",
    "\n",
    "        print(\"üìä Building data docs...\")\n",
    "        build_docs(context)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Writing Validation Rules for Data Ingestion\n",
    "\n",
    "### Define validation rules for an API data source to confirm that 'Status' field contains only predefined statuses ('Active', 'Inactive').\n",
    "\n",
    "- Apply `expect_column_values_to_be_in_set` to check field values during data ingestion.\n",
    "- Execute the validation and review any mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading GE context...\n",
      "‚ùå Error: Failed to load GE context: Error: No gx directory was found here!\n",
      "    - Please check that you are in the correct directory or have specified the correct directory.\n",
      "    - If you have never run Great Expectations in this project, please run `great_expectations init` to get started.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# write your code from here\n",
    "import great_expectations as ge\n",
    "import pandas as pd\n",
    "from great_expectations.data_context import FileDataContext\n",
    "from great_expectations.exceptions import GreatExpectationsError\n",
    "\n",
    "# === Configuration ===\n",
    "GE_PATH = \"great_expectations\"\n",
    "SUITE_NAME = \"api_data_suite\"\n",
    "DATASOURCE_NAME = \"api_datasource\"\n",
    "DATA_ASSET_NAME = \"api_response_data\"  # Logical name in GE\n",
    "CONNECTOR_NAME = \"default_runtime_data_connector_name\"\n",
    "\n",
    "# Sample API data for demo (replace with actual API data loading)\n",
    "api_data = [\n",
    "    {\"Status\": \"Active\", \"UserID\": 1},\n",
    "    {\"Status\": \"Inactive\", \"UserID\": 2},\n",
    "    {\"Status\": \"Pending\", \"UserID\": 3},  # <-- This will fail validation\n",
    "]\n",
    "\n",
    "# === Functions ===\n",
    "\n",
    "def load_context(path):\n",
    "    try:\n",
    "        return FileDataContext(path)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load GE context: {e}\")\n",
    "\n",
    "def get_validator_from_runtime(context, df, suite_name):\n",
    "    try:\n",
    "        validator = context.get_validator(\n",
    "            batch={\n",
    "                \"batch_data\": ge.from_pandas(df),\n",
    "                \"datasource_name\": DATASOURCE_NAME,\n",
    "                \"data_connector_name\": CONNECTOR_NAME,\n",
    "                \"data_asset_name\": DATA_ASSET_NAME,\n",
    "            },\n",
    "            expectation_suite_name=suite_name,\n",
    "        )\n",
    "        return validator\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to create validator: {e}\")\n",
    "\n",
    "def define_status_expectation(validator):\n",
    "    validator.expect_column_to_exist(\"Status\")\n",
    "    validator.expect_column_values_to_be_in_set(\"Status\", [\"Active\", \"Inactive\"])\n",
    "    validator.save_expectation_suite()\n",
    "\n",
    "def run_validation(validator):\n",
    "    result = validator.validate()\n",
    "    if result[\"success\"]:\n",
    "        print(\"‚úÖ All Status values are valid!\")\n",
    "    else:\n",
    "        print(\"‚ùå Validation failed! Mismatched Status values found:\")\n",
    "        for res in result[\"results\"]:\n",
    "            if not res[\"success\"]:\n",
    "                print(f\"- {res['expectation_config']['expectation_type']}: {res['expectation_config']['kwargs']}\")\n",
    "\n",
    "# === Main ===\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        print(\"üìÇ Loading GE context...\")\n",
    "        context = load_context(GE_PATH)\n",
    "\n",
    "        print(\"üìã Creating validator with runtime batch data...\")\n",
    "        df_api = pd.DataFrame(api_data)\n",
    "        validator = get_validator_from_runtime(context, df_api, SUITE_NAME)\n",
    "\n",
    "        print(\"üõ† Defining Status validation rule...\")\n",
    "        define_status_expectation(validator)\n",
    "\n",
    "        print(\"üöÄ Running validation...\")\n",
    "        run_validation(validator)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
